{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9793b20",
      "metadata": {
        "id": "a9793b20",
        "outputId": "f84c4f14-71c8-4c94-953a-dade01f0a450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 1920, 3)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 1665, 16)             12304     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 1665, 16)             12304     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 1665, 16)             12304     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 1410, 16)             65552     ['conv1d_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 1410, 16)             65552     ['conv1d_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)          (None, 1410, 16)             65552     ['conv1d_15[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1410, 48)             0         ['conv1d_16[0][0]',           \n",
            "                                                                     'conv1d_17[0][0]',           \n",
            "                                                                     'conv1d_18[0][0]']           \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 1410, 64)             3136      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 1410, 64)             4160      ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " separable_conv1d (Separabl  (None, 1920, 32)             131       ['input_4[0][0]']             \n",
            " eConv1D)                                                                                         \n",
            "                                                                                                  \n",
            " separable_conv1d_2 (Separa  (None, 1410, 32)             2144      ['dense_10[0][0]']            \n",
            " bleConv1D)                                                                                       \n",
            "                                                                                                  \n",
            " separable_conv1d_1 (Separa  (None, 1920, 32)             1088      ['separable_conv1d[0][0]']    \n",
            " bleConv1D)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 3330, 32)             0         ['separable_conv1d_2[0][0]',  \n",
            " )                                                                   'separable_conv1d_1[0][0]']  \n",
            "                                                                                                  \n",
            " instance_normalization_1 (  (None, 3330, 32)             0         ['concatenate_1[0][0]']       \n",
            " InstanceNormalization)                                                                           \n",
            "                                                                                                  \n",
            " patches (Patches)           (None, None, 2048)           0         ['instance_normalization_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " patch_encoder (PatchEncode  (None, None, 32)             65568     ['patches[0][0]']             \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, None, 32)             16800     ['patch_encoder[0][0]',       \n",
            " iHeadAttention)                                                     'patch_encoder[0][0]']       \n",
            "                                                                                                  \n",
            " add (Add)                   (None, None, 32)             0         ['multi_head_attention[0][0]',\n",
            "                                                                     'patch_encoder[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, None, 32)             64        ['add[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, None, 32)             1056      ['layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.gelu (TFOpLambda)     (None, None, 32)             0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, None, 32)             0         ['tf.nn.gelu[0][0]']          \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, None, 32)             1056      ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.gelu_1 (TFOpLambda)   (None, None, 32)             0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, None, 32)             0         ['tf.nn.gelu_1[0][0]']        \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, None, 32)             0         ['dropout_8[0][0]',           \n",
            "                                                                     'add[0][0]']                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, None, 32)             16800     ['add_1[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, None, 32)             0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, None, 32)             64        ['add_2[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, None, 32)             1056      ['layer_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " tf.nn.gelu_2 (TFOpLambda)   (None, None, 32)             0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, None, 32)             0         ['tf.nn.gelu_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, None, 32)             1056      ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.gelu_3 (TFOpLambda)   (None, None, 32)             0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, None, 32)             0         ['tf.nn.gelu_3[0][0]']        \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, None, 32)             0         ['dropout_10[0][0]',          \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, None, 32)             64        ['add_3[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 32)                   0         ['layer_normalization_2[0][0]'\n",
            " GlobalAveragePooling1D)                                            ]                             \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 256)                  8448      ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " tf.nn.gelu_4 (TFOpLambda)   (None, 256)                  0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 256)                  0         ['tf.nn.gelu_4[0][0]']        \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 128)                  32896     ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " tf.nn.gelu_5 (TFOpLambda)   (None, 128)                  0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 128)                  0         ['tf.nn.gelu_5[0][0]']        \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 1)                    129       ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 389284 (1.49 MB)\n",
            "Trainable params: 389284 (1.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#the following code was obtained from the original GitHib repository.\n",
        "#small changes were made to allow the code to run locally on a Windows computer.\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"C:\\\\Users\\Admin\\\\Desktop\\\\sleep_data\")\n",
        "import torch\n",
        "\n",
        "import keras\n",
        "from keras import Input, Model\n",
        "from keras.layers import Dense, Flatten, MaxPooling2D, Conv2D, BatchNormalization, LSTM, Bidirectional, Permute, \\\n",
        "    Reshape, GRU, Conv1D, MaxPooling1D, Activation, Dropout, GlobalAveragePooling1D, multiply, MultiHeadAttention, Add, \\\n",
        "    LayerNormalization, SeparableConvolution1D\n",
        "from keras.models import Sequential\n",
        "from keras.activations import relu, sigmoid\n",
        "from keras.regularizers import l2\n",
        "import tensorflow_addons as tfa\n",
        "#from .transformer import create_transformer_model, mlp, create_hybrid_transformer_model\n",
        "from transformer import create_transformer_model, mlp, create_hybrid_transformer_model\n",
        "\n",
        "\n",
        "\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    for i in range(5): # 10\n",
        "        model.add(Conv1D(45, 32, padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation(relu))\n",
        "        model.add(MaxPooling1D())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    for i in range(2): #4\n",
        "        model.add(Dense(512))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation(relu))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_cnnlstm_model(input_a_shape, weight=1e-3):\n",
        "    cnn_filters = 32 # 128\n",
        "    cnn_kernel_size = 4 # 4\n",
        "    input1 = Input(shape=input_a_shape)\n",
        "    input1 = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                              beta_initializer=\"glorot_uniform\",\n",
        "                                              gamma_initializer=\"glorot_uniform\")(input1)\n",
        "    x1 = Conv1D(cnn_filters, cnn_kernel_size, activation='relu')(input1)\n",
        "    x1 = Conv1D(cnn_filters, cnn_kernel_size, activation='relu')(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    x1 = Conv1D(cnn_filters, cnn_kernel_size, activation='relu')(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    x1 = Conv1D(cnn_filters, cnn_kernel_size, activation='relu')(x1)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    x1 = LSTM(32, return_sequences=True)(x1) #256\n",
        "    x1 = LSTM(32, return_sequences=True)(x1) #256\n",
        "    x1 = LSTM(32)(x1) #256\n",
        "    x1 = Flatten()(x1)\n",
        "\n",
        "    x1 = Dense(32, activation='relu')(x1) #64\n",
        "    x1 = Dense(32, activation='relu')(x1) #64\n",
        "    outputs = Dense(1, activation='sigmoid')(x1)\n",
        "\n",
        "    model = Model(inputs=input1, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_semscnn_model(input_a_shape):\n",
        "    input1 = Input(shape=input_a_shape)\n",
        "    # input1 = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "    #                                           beta_initializer=\"glorot_uniform\",\n",
        "    #                                           gamma_initializer=\"glorot_uniform\")(input1)\n",
        "    x1 = Conv1D(45, 32, strides=1)(input1) #kernel_size=11\n",
        "    x1 = Conv1D(45, 32, strides=2)(x1) #64 kernel_size=11\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation(relu)(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    x1 = Conv1D(45, 32, strides=2)(x1) #64 kernel_size=11\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation(relu)(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    x1 = Conv1D(45, 32, strides=2)(x1) #64 kernel_size=11\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation(relu)(x1)\n",
        "    x1 = MaxPooling1D()(x1)\n",
        "\n",
        "    squeeze = Flatten()(x1)\n",
        "    excitation = Dense(128, activation='relu')(squeeze)\n",
        "    excitation = Dense(64, activation='relu')(excitation)\n",
        "    logits = Dense(1, activation='sigmoid')(excitation)\n",
        "    model = Model(inputs=input1, outputs=logits)\n",
        "    return model\n",
        "\n",
        "\n",
        "model_dict = {\n",
        "\n",
        "    \"cnn\": create_cnn_model((60 * 32, 3)),\n",
        "    \"sem-mscnn\": create_semscnn_model((60 * 32, 3)),\n",
        "    \"cnn-lstm\": create_cnnlstm_model((60 * 32, 3)),\n",
        "    \"hybrid\": create_hybrid_transformer_model((60 * 32, 3)),\n",
        "}\n",
        "\n",
        "\n",
        "def get_model(config):\n",
        "    if config[\"model_name\"].split('_')[0] == \"Transformer\":\n",
        "        return create_transformer_model(input_shape=(60 * 32, len(config[\"channels\"])),\n",
        "                                        num_patches=config[\"num_patches\"], projection_dim=config[\"transformer_units\"],\n",
        "                                        transformer_layers=config[\"transformer_layers\"], num_heads=config[\"num_heads\"],\n",
        "                                        transformer_units=[config[\"transformer_units\"] * 2,\n",
        "                                                           config[\"transformer_units\"]],\n",
        "                                        mlp_head_units=[256, 128], num_classes=1, drop_out=config[\"drop_out_rate\"],\n",
        "                                        reg=config[\"regression\"], l2_weight=config[\"regularization_weight\"])\n",
        "    else:\n",
        "        return model_dict.get(config[\"model_name\"].split('_')[0])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {\n",
        "        \"model_name\": \"hybrid\",\n",
        "        \"regression\": False,\n",
        "\n",
        "        \"transformer_layers\": 4,  # best 5\n",
        "        \"drop_out_rate\": 0.25,\n",
        "        \"num_patches\": 20,  # best\n",
        "        \"transformer_units\": 32,  # best 32\n",
        "        \"regularization_weight\": 0.001,  # best 0.001\n",
        "        \"num_heads\": 4,\n",
        "        \"epochs\": 100,  # best\n",
        "        \"channels\": [14, 18, 19, 20],\n",
        "    }\n",
        "    model = get_model(config)\n",
        "    model.build(input_shape=(1, 60 * 32, 10))\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "\n",
        "    #########################\n",
        "    torch.save(model, \"C:\\\\Users\\\\Admin\\\\Desktop\\\\sleep_data\\\\savedmodel.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ec01ac",
      "metadata": {
        "id": "09ec01ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e17583b",
      "metadata": {
        "id": "2e17583b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}